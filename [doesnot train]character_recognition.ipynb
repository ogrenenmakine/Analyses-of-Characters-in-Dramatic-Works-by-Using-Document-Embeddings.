{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-based Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd\n",
    "from mxnet.gluon.utils import download\n",
    "import gluonnlp\n",
    "import nltk\n",
    "from gluonnlp.data import batchify\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from mxnet.gluon import Block, nn, rnn\n",
    "\n",
    "import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [mx.gpu(0)]\n",
    "log_interval = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "lr = 20\n",
    "epochs = 3\n",
    "bptt = 35\n",
    "grad_clip = 0.25"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import glob\n",
    "g = open(\"data/othello.txt\", \"a\")\n",
    "filenames = glob.glob(\"data/Othello/*.txt\")\n",
    "for fn in filenames:\n",
    "    filename = fn.split('/')[-1]\n",
    "    with open('data/Othello/'+filename) as f:\n",
    "        content = f.readlines()\n",
    "    for c in content:\n",
    "        g.write(c.replace('\\n','') + '\\t' + str(filenames.index(fn)) + '\\n')\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moses_tokenizer = nlp.data.SacreMosesTokenizer()\n",
    "\n",
    "all_datasets = nlp.data.CorpusDataset(\n",
    "        'data/all.txt',\n",
    "        sample_splitter=nltk.tokenize.sent_tokenize,\n",
    "        tokenizer=moses_tokenizer,\n",
    "        flatten=True,\n",
    "        eos='<eos>')\n",
    "vocab = nlp.Vocab(\n",
    "    nlp.data.Counter(all_datasets), padding_token=None, bos_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_train = gluonnlp.data.dataset.TSVDataset('data/hamlet_train.txt')\n",
    "hamlet_val = gluonnlp.data.dataset.TSVDataset('data/hamlet_val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nlp.data.SpacyTokenizer('en')\n",
    "length_clip = nlp.data.ClipSequence(35)\n",
    "length_pad = nlp.data.PadSequence(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    data, label = x\n",
    "    label = int(label)\n",
    "    data = length_clip(tokenizer(data))\n",
    "    data = length_pad(data)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    start = time.time()\n",
    "    pool = mp.Pool()\n",
    "    dataset = gluon.data.SimpleDataset(pool.map(preprocess, dataset))\n",
    "    end = time.time()\n",
    "    print('Done! Tokenizing Time={:.2f}s, #Sentences={}'.format(end - start, len(dataset)))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = preprocess_dataset(hamlet_train)\n",
    "val_dataset = preprocess_dataset(hamlet_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_idx(x):\n",
    "    return vocab[x[0]], x[1]\n",
    "\n",
    "pool = mp.Pool()\n",
    "train_dataset = pool.map(token_to_idx, train_dataset)\n",
    "val_dataset = pool.map(token_to_idx, val_dataset)\n",
    "pool.close()\n",
    "print(train_dataset[0][0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchify_fn = nlp.data.batchify.Tuple(nlp.data.batchify.Pad(axis=0),nlp.data.batchify.Stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = gluon.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, batchify_fn=batchify_fn)\n",
    "val_dataloader = gluon.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, batchify_fn=batchify_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(gluon.Block):\n",
    "    def __init__(self, vocab_size, num_embed, num_hidden, num_layers, dropout=0.2, tie_weights=False, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.embedding = nn.HybridSequential()\n",
    "        with self.embedding.name_scope():\n",
    "            self.embedding.add(nn.Embedding(vocab_size, num_embed))\n",
    "            self.embedding.add(nn.Dropout(0.2))\n",
    "        with self.name_scope():\n",
    "            self.encoder = rnn.LSTM(num_hidden, num_layers, dropout=dropout,input_size=num_embed)\n",
    "            \n",
    "    def forward(self, inputs, hidden):\n",
    "        output, hidden = self.encoder(self.embedding(inputs), hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.encoder.begin_state(*args, **kwargs)\n",
    "\n",
    "model = RNNModel(len(vocab), 200, 200, 2)\n",
    "model.load_parameters(\"standard_lstm_lm_200-6.params\",ignore_extra=True,ctx=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(gluon.Block):\n",
    "    def __init__(self, num_hidden, **kwargs):\n",
    "        super(DenseLayer, self).__init__(**kwargs)\n",
    "        self.decoder = nn.HybridSequential()\n",
    "        with self.decoder.name_scope():\n",
    "            self.decoder.add(nn.Dense(units=10,flatten=True))\n",
    "            \n",
    "    def forward(self, inputs):\n",
    "        return self.decoder(inputs)\n",
    "\n",
    "dense = DenseLayer(200)\n",
    "dense.collect_params().initialize(mx.init.Xavier(magnitude=2.24),ctx=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer and optimizer and specify some hyperparameters\n",
    "trainer = gluon.Trainer(model.collect_params(), 'Adam', {\n",
    "    'learning_rate': lr,\n",
    "    'wd': 0.001\n",
    "})\n",
    "\n",
    "# Specify the loss function, in this case, cross-entropy with softmax.\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach(hidden):\n",
    "    if isinstance(hidden, (tuple, list)):\n",
    "        hidden = [detach(i) for i in hidden]\n",
    "    else:\n",
    "        hidden = hidden.detach()\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that ctx is short for context\n",
    "def evaluate(model, data_source, batch_size, ctx):\n",
    "    total_L = 0.0\n",
    "    ntotal = 0\n",
    "    for i, (data, target) in enumerate(train_dataloader):\n",
    "        data = data.as_in_context(context[0])\n",
    "        data = mx.nd.transpose(data)\n",
    "        target = target.as_in_context(context[0])\n",
    "        hidden = model.begin_state(batch_size=data.shape[1], func=mx.nd.zeros, ctx=context[0])\n",
    "        output, hidden = model(data, hidden)\n",
    "        hidden = detach(hidden)\n",
    "        classes = dense(output[-1,:,:])\n",
    "        L = loss(classes, target)\n",
    "        total_L += mx.nd.sum(L).asscalar()\n",
    "        ntotal += L.size\n",
    "    return total_L / ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for actually training the model\n",
    "def train(model, train_data, val_data, epochs, lr):\n",
    "    best_val = float(\"Inf\")\n",
    "    start_train_time = time.time()\n",
    "    parameters = model.collect_params().values()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_L = 0.0\n",
    "        ntotal = 0\n",
    "        start_epoch_time = time.time()\n",
    "        start_log_interval_time = time.time()\n",
    "\n",
    "        for i, (data, target) in enumerate(train_data):\n",
    "            data = data.as_in_context(context[0])\n",
    "            data = mx.nd.transpose(data)\n",
    "            target = target.as_in_context(context[0])\n",
    "            hidden = model.begin_state(batch_size=data.shape[1], func=mx.nd.zeros, ctx=context[0])\n",
    "            L = 0\n",
    "            with autograd.record():\n",
    "                output, hidden = model(data, hidden)\n",
    "                hidden = detach(hidden)\n",
    "                classes = dense(output[-1,:,:])\n",
    "                L = loss(classes, target)\n",
    "            L.backward()\n",
    "            trainer.step(1)\n",
    "            \n",
    "            total_L += mx.nd.sum(L).asscalar()\n",
    "            ntotal += L.size            \n",
    "\n",
    "            if i % log_interval == 0 and i > 0:\n",
    "                cur_L = total_L / log_interval\n",
    "                print('[Epoch %d Batch %d/%d] loss %.2f, ppl %.2f, '\n",
    "                      'throughput %.2f samples/s'%(\n",
    "                    epoch, i, len(train_data), cur_L, math.exp(cur_L),\n",
    "                    batch_size * log_interval / (time.time() - start_log_interval_time)))\n",
    "                total_L = 0.0\n",
    "                start_log_interval_time = time.time()\n",
    "\n",
    "        mx.nd.waitall()\n",
    "\n",
    "        print('[Epoch %d] throughput %.2f samples/s'%(\n",
    "                    epoch, len(train_data)*batch_size / (time.time() - start_epoch_time)))\n",
    "\n",
    "        val_L = evaluate(model, val_data, batch_size, context[0])\n",
    "        print('[Epoch %d] time cost %.2fs, valid loss %.2f, valid ppl %.2f'%(\n",
    "            epoch, time.time()-start_epoch_time, val_L, math.exp(val_L)))\n",
    "\n",
    "        if val_L < best_val:\n",
    "            best_val = val_L\n",
    "            #model.save_parameters('cr-{}.params'.format(epoch))\n",
    "            print('Model saved!')\n",
    "        else:\n",
    "            lr = lr*0.25\n",
    "            print('Learning rate now %f'%(lr))\n",
    "            trainer.set_learning_rate(lr)\n",
    "\n",
    "    print('Total training throughput %.2f samples/s'%(\n",
    "                            (batch_size * len(train_data) * epochs) /\n",
    "                            (time.time() - start_train_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_dataloader, batch_size, context[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    epochs=12,\n",
    "    lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
